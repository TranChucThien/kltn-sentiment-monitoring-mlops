# how to run this file
# python pipeline.py all        # Cháº¡y toÃ n bá»™ pipeline
# python pipeline.py dataset    # Chá»‰ chuáº©n bá»‹ dá»¯ liá»‡u
# python pipeline.py train      # Chá»‰ train
# python pipeline.py eval       # Chá»‰ evaluate

import argparse
from src._01_dataset_preparation import main as dataset_main
from src._02_training import main as training_main
from src._03_evaluate import main as evaluate_main

def run_dataset():
    print("ðŸ“¦ Running Dataset Preparation...")
    dataset_main()

def run_training():
    print("ðŸ§  Running Training...")
    cv_version, tf_version = training_main()
    print(f"âœ… Training done: CV v{cv_version}, TF v{tf_version}")

def run_evaluate():
    print("ðŸ“Š Running Evaluation...")
    cv_version, tf_version = training_main()  # hoáº·c load version tá»« file
    evaluate_main(name="CountVectorizer_Model", version=cv_version)
    evaluate_main(name="HashingTF_IDF_Model", version=tf_version)

def main():
    parser = argparse.ArgumentParser(description="ML Pipeline CLI")
    parser.add_argument("step", choices=["all", "dataset", "train", "eval"],
                        help="Which step to run")

    args = parser.parse_args()

    if args.step == "all":
        run_dataset()
        run_training()
        run_evaluate()
    elif args.step == "dataset":
        run_dataset()
    elif args.step == "train":
        run_training()
    elif args.step == "eval":
        run_evaluate()

        

if __name__ == "__main__":
    main()

