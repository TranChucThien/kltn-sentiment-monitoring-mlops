{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558a9048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thientran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/thientran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from utils.s3_process import  read_key\n",
    "from utils.s3_process_nlp import read_csv_from_s3, get_latest_s3_object_version\n",
    "from utils.clean_text import clean_text_column\n",
    "\n",
    "from utils.mlflow_func import get_latest_model_version, get_model_version_by_stage\n",
    "import datetime\n",
    "import yaml\n",
    "import mlflow\n",
    "import os \n",
    "import time\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI']=\"https://dagshub.com/TranChucThien/kltn-sentiment-monitoring-mlops.mlflow\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']=\"TranChucThien\"\n",
    "\n",
    "\n",
    "# Thêm các thư viện cần thiết\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Các import khác...\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "# \n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "# \n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import sys\n",
    "from multiprocessing import Process\n",
    "import logging\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fddba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "    \n",
    "    document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([\"document\"]) \\\n",
    "        .setOutputCol(\"token\")\n",
    "        \n",
    "    normalizer = Normalizer() \\\n",
    "        .setInputCols([\"token\"]) \\\n",
    "        .setOutputCol(\"normalized\") \\\n",
    "        .setLowercase(True) \n",
    "        \n",
    "    stop_words_cleaner = StopWordsCleaner() \\\n",
    "        .setInputCols([\"normalized\"]) \\\n",
    "        .setOutputCol(\"cleanTokens\") \\\n",
    "        .setCaseSensitive(False)\n",
    "    \n",
    "    lemmatizer = LemmatizerModel.pretrained(\"lemma_antbnc\") \\\n",
    "        .setInputCols([\"cleanTokens\"]) \\\n",
    "        .setOutputCol(\"lemmatized\") \n",
    "            \n",
    "    word_embeddings_elmo = ElmoEmbeddings.pretrained(\"elmo\", \"en\") \\\n",
    "        .setInputCols([\"document\", \"lemmatized\"]) \\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    sentence_embeddings = SentenceEmbeddings() \\\n",
    "        .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"sentence_embeddings\") \\\n",
    "        .setPoolingStrategy(\"SUM\")  # or \"SUM\", \"MAX\"\n",
    "        \n",
    "    classifier = ClassifierDLApproach() \\\n",
    "        .setInputCols([\"sentence_embeddings\"]) \\\n",
    "        .setOutputCol(\"category\") \\\n",
    "        .setLabelColumn(\"label\") \\\n",
    "        .setMaxEpochs(10) \\\n",
    "        .setLr(0.003) \\\n",
    "        .setBatchSize(8) \\\n",
    "        .setEnableOutputLogs(True) \\\n",
    "        .setOutputLogsPath(\"classifier_logs\")\n",
    "    \n",
    "    finisher = Finisher() \\\n",
    "        .setInputCols([\"category\"]) \\\n",
    "        .setOutputCols([\"prediction\"]) \\\n",
    "        .setCleanAnnotations(False) \\\n",
    "        \n",
    "        \n",
    "    pipeline_elmo = Pipeline(stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        normalizer,\n",
    "        stop_words_cleaner,\n",
    "        lemmatizer,\n",
    "        word_embeddings_elmo,\n",
    "        sentence_embeddings,\n",
    "        classifier,\n",
    "        finisher\n",
    "    ])\n",
    "    return pipeline_elmo\n",
    "\n",
    "\n",
    "def tune_model(pipeline, train_data, use_hashing=True, vectorizer=None, hashingTF=None, lr=None):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    paramGrid = ParamGridBuilder()\n",
    "\n",
    "    if use_hashing:\n",
    "        paramGrid = paramGrid.addGrid(hashingTF.numFeatures, [1000, 5000, 10000])\n",
    "    else:\n",
    "        paramGrid = paramGrid.addGrid(vectorizer.vocabSize, [5000, 10000])\n",
    "\n",
    "    paramGrid = paramGrid.addGrid(lr.regParam, [0.0, 0.01, 0.1])\n",
    "    paramGrid = paramGrid.build()\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3\n",
    "    )\n",
    "\n",
    "    best_model = crossval.fit(train_data)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "\n",
    "def evaluator(prediction1, label_col=\"label\", prediction_col=\"prediction\"):\n",
    "    prediction1 = prediction1.withColumn(label_col, col(label_col).cast(DoubleType()))\n",
    "    prediction1 = prediction1.withColumn(prediction_col, col(prediction_col).cast(DoubleType()))\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=prediction_col)\n",
    "    accuracy = evaluator.evaluate(prediction1, {evaluator.metricName: \"accuracy\"})\n",
    "    precision = evaluator.evaluate(prediction1, {evaluator.metricName: \"weightedPrecision\"})\n",
    "    recall = evaluator.evaluate(prediction1, {evaluator.metricName: \"weightedRecall\"})\n",
    "    f1 = evaluator.evaluate(prediction1, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def data_distribution(data, label_col=\"Label\"):\n",
    "    total_count = data.count()\n",
    "    label_dist = data.groupBy(label_col).count()\n",
    "    label_dist = label_dist.withColumn(\"percentage\", (col(\"count\") / total_count) * 100)\n",
    "    label_dist.orderBy(label_col).show()\n",
    "    return label_dist.orderBy(label_col)\n",
    "\n",
    "def load_config(config_path=\"configs/config.yaml\"):       \n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load config: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def set_up_mlflow_tracking(config, config_secret):\n",
    "    \"\"\"Sets up MLflow tracking URI and credentials.\"\"\"\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = config_secret['mlflow']['password']\n",
    "    os.environ['MLFLOW_TRACKING_URI'] = config['mlflow']['tracking_uri']\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME'] = config['mlflow']['username']\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    logging.info(\"MLflow tracking setup complete.\")\n",
    "    \n",
    "def load_dataset(config, config_secret, spark):\n",
    "    \"\"\"Loads dataset from S3.\"\"\"\n",
    "    bucket = config['s3']['bucket']\n",
    "    dataset_key = config['s3']['keys']['dataset']\n",
    "    \n",
    "    dataset_path = f\"s3a://{bucket}/{dataset_key}\"\n",
    "    logging.info(f\"Dataset path: {dataset_path}\")\n",
    "    # AWS credentials and region\n",
    "    AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY = read_key(config_secret['aws']['access_key_path'])\n",
    "    AWS_REGION = config['aws']['region']\n",
    "    S3_OUTPUT_KEY = config['s3']['keys']['dataset']\n",
    "    BUCKET_NAME = config['s3']['bucket']\n",
    "    \n",
    "    logging.info(\"Reading CSV file from S3...\")\n",
    "    data = read_csv_from_s3(dataset_path, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, spark)\n",
    "    logging.info(\"Read csv file from S3 successfully.\")\n",
    "    data.show(3)\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_version(config, config_secret):\n",
    "    \"\"\"Loads dataset from S3.\"\"\"\n",
    "    bucket = config['s3']['bucket']\n",
    "    dataset_key = config['s3']['keys']['dataset']\n",
    "    \n",
    "    dataset_path = f\"s3a://{bucket}/{dataset_key}\"\n",
    "    logging.info(f\"Dataset path: {dataset_path}\")\n",
    "    # AWS credentials and region\n",
    "    AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY = read_key(config_secret['aws']['access_key_path'])\n",
    "    AWS_REGION = config['aws']['region']\n",
    "    S3_OUTPUT_KEY = config['s3']['keys']['dataset']\n",
    "    BUCKET_NAME = config['s3']['bucket']\n",
    "    \n",
    "    return get_latest_s3_object_version(s3_path=dataset_path,aws_access_key=AWS_ACCESS_KEY_ID,aws_secret_key=AWS_SECRET_ACCESS_KEY,region=AWS_REGION), dataset_path\n",
    "\n",
    "def split_data(data, train_ratio=0.8, seed=42):\n",
    "    train_data, validate_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "    logging.info(\"Data split completed.\")\n",
    "    \n",
    "    print(\"Train data:\")\n",
    "    train_data.printSchema()\n",
    "    train_data.show(3)\n",
    "    \n",
    "    print(\"Validate data:\")\n",
    "    validate_data.printSchema()\n",
    "    validate_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d916ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:25:27,344 - INFO - Starting Text Classification Pipeline for Olmo model...\n",
      "2025-06-04 10:25:27,346 - INFO - Loading configuration from 'configs/config.yaml'\n",
      "2025-06-04 10:25:27,373 - INFO - Successfully loaded configuration.\n",
      "2025-06-04 10:25:27,374 - INFO - Initializing Spark session...\n",
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/06/04 10:25:29 WARN Utils: Your hostname, LE11-D5013 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/06/04 10:25:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/thientran/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/thientran/.ivy2/cache\n",
      "The jars for the packages stored in: /home/thientran/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-bb1b2e9b-379b-4930-b6d4-c68a38695a9f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in spark-list\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      ":: resolution report :: resolve 1889ms :: artifacts dl 78ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from spark-list in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   86  |   0   |   0   |   5   ||   81  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-bb1b2e9b-379b-4930-b6d4-c68a38695a9f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 81 already retrieved (0kB/32ms)\n",
      "25/06/04 10:25:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 10:25:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "2025-06-04 10:25:43,291 - INFO - Spark Session with Spark NLP is ready.\n",
      "2025-06-04 10:25:43,292 - INFO - Loading dataset from S3...\n",
      "2025-06-04 10:25:43,293 - INFO - Dataset path: s3a://tranchucthien-bucket/dataset/dataset.csv\n",
      "2025-06-04 10:25:43,495 - INFO - Reading CSV file from S3...\n",
      "25/06/04 10:25:43 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "2025-06-04 10:26:03,581 - INFO - Read csv file from S3 successfully.            \n",
      "2025-06-04 10:26:05,089 - INFO - Dataset path: s3a://tranchucthien-bucket/dataset/dataset.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Label|                Text|\n",
      "+-----+--------------------+\n",
      "|    1|im getting border...|\n",
      "|    1|im coming borderl...|\n",
      "|    1|im getting border...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:26:06,597 - INFO - Successfully loaded dataset.\n"
     ]
    }
   ],
   "source": [
    "# Configure logging within this process\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info(f\"Starting Text Classification Pipeline for Olmo model...\")\n",
    "\n",
    "\n",
    "# Load configuration\n",
    "logging.info(\"Loading configuration from 'configs/config.yaml'\")\n",
    "config = load_config(\"../configs/config.yaml\")\n",
    "config_secret = load_config(\"../configs/secrets.yaml\")\n",
    "logging.info(\"Successfully loaded configuration.\")\n",
    "\n",
    "# Spark session initialization\n",
    "logging.info(\"Initializing Spark session...\")\n",
    "spark = sparknlp.start(\n",
    "    SparkSession.builder \\\n",
    "        .appName(\"Spark NLP - BERT Sentiment Classification\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "        .getOrCreate()\n",
    ")\n",
    "logging.info(\"Spark Session with Spark NLP is ready.\")\n",
    "\n",
    "# Load dataset\n",
    "logging.info(\"Loading dataset from S3...\")\n",
    "data = load_dataset(config, config_secret, spark)\n",
    "data_version, dataset_path = get_data_version(config, config_secret)\n",
    "\n",
    "data = data.withColumnRenamed(\"text\", \"text\").withColumnRenamed(\"label\", \"label\")\n",
    "data = data.selectExpr(\"cast(Text as string) as text\", \"cast(Label as string) as label\")\n",
    "data = data.filter(col(\"label\") != \"3\")\n",
    "logging.info(\"Successfully loaded dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77fc8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:26:06,607 - INFO - Setting up MLflow experiment...\n",
      "2025-06-04 10:26:06,610 - INFO - MLflow tracking setup complete.\n",
      "2025-06-04 10:26:08,817 - INFO - MLflow experiment set up successfully with name: DL_Elmo_Text_Classification_Experiment\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Setting up MLflow experiment...\")\n",
    "set_up_mlflow_tracking(config=config, config_secret=config_secret)\n",
    "experiment_name = f'DL_Elmo_Text_Classification_Experiment'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "logging.info(\"MLflow experiment set up successfully with name: %s\", experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8af181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:26:20,265 - INFO - Total samples: 59497                           \n"
     ]
    }
   ],
   "source": [
    "total_count = data.count()\n",
    "logging.info(f\"Total samples: {data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe66ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def k_fold_split(data, k=3, seed=42):\n",
    "    # Chia dữ liệu thành k phần bằng randomSplit\n",
    "    weights = [1.0 / k] * k\n",
    "    return data.randomSplit(weights, seed=seed)\n",
    "\n",
    "def cross_validate_custom(data, pipeline, k=3):\n",
    "    folds = k_fold_split(data, k)\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(k):\n",
    "        logging.info(f\"=== Fold {i + 1}/{k} ===\")\n",
    "        validate_data = folds[i]\n",
    "        # Lấy tất cả các fold ngoại trừ fold[i] làm train\n",
    "        train_folds = [folds[j] for j in range(k) if j != i]\n",
    "        train_data = reduce(lambda df1, df2: df1.union(df2), train_folds)\n",
    "\n",
    "        model = pipeline.fit(train_data)\n",
    "        prediction = model.transform(validate_data).withColumn(\"prediction\", col(\"prediction\")[0].cast(\"string\"))\n",
    "        accuracy, precision, recall, f1 = evaluator(prediction, label_col=\"label\", prediction_col=\"prediction\")\n",
    "        metrics.append((accuracy, precision, recall, f1))\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f4688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validate_data = data.randomSplit([0.9, 0.1], seed=42)\n",
    "a,b =  validate_data.randomSplit([0.9, 0.1], seed=42)\n",
    "print(\"Count train data:\", b.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11386444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:10:16,319 - INFO - === Fold 1/5 ===\n",
      "2025-06-04 14:15:54.260265: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/9c16db13d6b4_classifier_dl9842502838296282843\n",
      "2025-06-04 14:15:55.096785: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-04 14:15:55.096949: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/9c16db13d6b4_classifier_dl9842502838296282843\n",
      "2025-06-04 14:15:56.114249: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-04 14:15:57.157219: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/9c16db13d6b4_classifier_dl9842502838296282843\n",
      "2025-06-04 14:15:57.311500: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 3051509 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 10 - learning_rate: 0.003 - batch_size: 8 - training_examples: 47528 - classes: 3\n",
      "Epoch 1/10 - 27.69s - loss: 7199.6724 - acc: 0.33767465 - batches: 5941\n",
      "Epoch 2/10 - 27.50s - loss: 5642.485 - acc: 0.60122454 - batches: 5941\n",
      "Epoch 3/10 - 27.71s - loss: 4953.927 - acc: 0.7173666 - batches: 5941\n",
      "Epoch 4/10 - 30.40s - loss: 4633.6206 - acc: 0.7736282 - batches: 5941\n",
      "Epoch 5/10 - 31.90s - loss: 4417.34 - acc: 0.8114585 - batches: 5941\n",
      "Epoch 6/10 - 33.83s - loss: 4257.999 - acc: 0.83599144 - batches: 5941\n",
      "Epoch 7/10 - 32.96s - loss: 4153.5117 - acc: 0.85490656 - batches: 5941\n",
      "Epoch 8/10 - 35.45s - loss: 4081.1377 - acc: 0.86744654 - batches: 5941\n",
      "Epoch 9/10 - 30.51s - loss: 4033.9739 - acc: 0.8763045 - batches: 5941\n",
      "Epoch 10/10 - 30.55s - loss: 3999.4333 - acc: 0.8826797 - batches: 5941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:28:46,934 - INFO - === Fold 2/5 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7952\n",
      "Precision: 0.7953\n",
      "Recall:    0.7952\n",
      "F1-score:  0.7942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:34:12.560927: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/4fce709856d1_classifier_dl12574968973225978250\n",
      "2025-06-04 14:34:12.693493: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-04 14:34:12.693566: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/4fce709856d1_classifier_dl12574968973225978250\n",
      "2025-06-04 14:34:13.185148: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-04 14:34:14.255207: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/4fce709856d1_classifier_dl12574968973225978250\n",
      "2025-06-04 14:34:14.430018: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1869118 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 10 - learning_rate: 0.003 - batch_size: 8 - training_examples: 47681 - classes: 3\n",
      "Epoch 1/10 - 27.03s - loss: 7213.961 - acc: 0.33596897 - batches: 5961\n",
      "Epoch 2/10 - 27.07s - loss: 7214.3447 - acc: 0.33598992 - batches: 5961\n",
      "Epoch 3/10 - 27.81s - loss: 5816.062 - acc: 0.5653523 - batches: 5961\n",
      "Epoch 4/10 - 29.90s - loss: 5011.707 - acc: 0.7068582 - batches: 5961\n",
      "Epoch 5/10 - 30.18s - loss: 4724.38 - acc: 0.7635277 - batches: 5961\n",
      "Epoch 6/10 - 34.81s - loss: 4492.475 - acc: 0.8011116 - batches: 5961\n",
      "Epoch 7/10 - 36.17s - loss: 4350.3945 - acc: 0.82487416 - batches: 5961\n",
      "Epoch 8/10 - 32.59s - loss: 4235.672 - acc: 0.8440436 - batches: 5961\n",
      "Epoch 9/10 - 30.04s - loss: 4155.3413 - acc: 0.85677433 - batches: 5961\n",
      "Epoch 10/10 - 29.08s - loss: 4094.221 - acc: 0.867219 - batches: 5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:48:18,847 - INFO - === Fold 3/5 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7910\n",
      "Precision: 0.7907\n",
      "Recall:    0.7910\n",
      "F1-score:  0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:53:44.607590: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/b49e1a200b76_classifier_dl9300862913484838846\n",
      "2025-06-04 14:53:44.729043: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-04 14:53:44.729117: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/b49e1a200b76_classifier_dl9300862913484838846\n",
      "2025-06-04 14:53:45.227057: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-04 14:53:46.100061: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/b49e1a200b76_classifier_dl9300862913484838846\n",
      "2025-06-04 14:53:46.259171: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1651596 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 10 - learning_rate: 0.003 - batch_size: 8 - training_examples: 47468 - classes: 3\n",
      "Epoch 1/10 - 30.26s - loss: 5658.344 - acc: 0.58530676 - batches: 5934\n",
      "Epoch 2/10 - 33.58s - loss: 4957.1387 - acc: 0.709759 - batches: 5934\n",
      "Epoch 3/10 - 32.24s - loss: 4600.983 - acc: 0.77243805 - batches: 5934\n",
      "Epoch 4/10 - 28.95s - loss: 4364.447 - acc: 0.8136693 - batches: 5934\n",
      "Epoch 5/10 - 30.59s - loss: 4201.317 - acc: 0.84200656 - batches: 5934\n",
      "Epoch 6/10 - 31.13s - loss: 4092.3135 - acc: 0.8618532 - batches: 5934\n",
      "Epoch 7/10 - 34.97s - loss: 4008.0015 - acc: 0.87622195 - batches: 5934\n",
      "Epoch 8/10 - 29.99s - loss: 3947.448 - acc: 0.88471264 - batches: 5934\n",
      "Epoch 9/10 - 28.42s - loss: 3909.2463 - acc: 0.8920656 - batches: 5934\n",
      "Epoch 10/10 - 31.90s - loss: 3888.4165 - acc: 0.89724845 - batches: 5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:06:15,506 - INFO - === Fold 4/5 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8133\n",
      "Precision: 0.8133\n",
      "Recall:    0.8133\n",
      "F1-score:  0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:12:24.448600: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/0aeae0af1179_classifier_dl15331463003606686069\n",
      "2025-06-04 15:12:24.582440: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-04 15:12:24.582508: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/0aeae0af1179_classifier_dl15331463003606686069\n",
      "2025-06-04 15:12:25.133126: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-04 15:12:26.306516: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/0aeae0af1179_classifier_dl15331463003606686069\n",
      "2025-06-04 15:12:26.471172: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2022582 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 10 - learning_rate: 0.003 - batch_size: 8 - training_examples: 47709 - classes: 3\n",
      "Epoch 1/10 - 28.49s - loss: 7570.494 - acc: 0.2944994 - batches: 5964\n",
      "Epoch 2/10 - 28.47s - loss: 7569.6284 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 3/10 - 31.63s - loss: 7569.4673 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 4/10 - 35.06s - loss: 7569.4214 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 5/10 - 30.67s - loss: 7569.4136 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 6/10 - 29.77s - loss: 7569.412 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 7/10 - 34.62s - loss: 7569.412 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 8/10 - 32.51s - loss: 7569.412 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 9/10 - 38.16s - loss: 7569.4116 - acc: 0.29452038 - batches: 5964\n",
      "Epoch 10/10 - 30.08s - loss: 7569.4116 - acc: 0.29452038 - batches: 5964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:25:17,113 - INFO - === Fold 5/5 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.2991\n",
      "Precision: 0.0895\n",
      "Recall:    0.2991\n",
      "F1-score:  0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:30:35.951814: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/42a07aedb599_classifier_dl15316262005986145512\n",
      "2025-06-04 15:30:36.065159: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-04 15:30:36.065228: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/42a07aedb599_classifier_dl15316262005986145512\n",
      "2025-06-04 15:30:36.505904: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-04 15:30:37.273898: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/42a07aedb599_classifier_dl15316262005986145512\n",
      "2025-06-04 15:30:37.421947: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1470142 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 10 - learning_rate: 0.003 - batch_size: 8 - training_examples: 47602 - classes: 3\n",
      "Epoch 1/10 - 27.76s - loss: 7087.7466 - acc: 0.35737395 - batches: 5951\n",
      "Epoch 2/10 - 27.26s - loss: 5273.9336 - acc: 0.6487605 - batches: 5951\n",
      "Epoch 3/10 - 28.62s - loss: 4879.205 - acc: 0.7222059 - batches: 5951\n",
      "Epoch 4/10 - 29.95s - loss: 4560.129 - acc: 0.7771429 - batches: 5951\n",
      "Epoch 5/10 - 29.22s - loss: 4358.7744 - acc: 0.81334037 - batches: 5951\n",
      "Epoch 6/10 - 29.64s - loss: 4205.1816 - acc: 0.8366386 - batches: 5951\n",
      "Epoch 7/10 - 31.39s - loss: 4121.002 - acc: 0.8532983 - batches: 5951\n",
      "Epoch 8/10 - 32.91s - loss: 4058.8323 - acc: 0.8655672 - batches: 5951\n",
      "Epoch 9/10 - 30.35s - loss: 4002.6511 - acc: 0.8752521 - batches: 5951\n",
      "Epoch 10/10 - 30.25s - loss: 3959.205 - acc: 0.8821008 - batches: 5951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 140:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7938\n",
      "Precision: 0.7943\n",
      "Recall:    0.7938\n",
      "F1-score:  0.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "metrics = cross_validate_custom(data, pipeline, k=5)  # hoặc k=5 tùy bạn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7936cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8028\n",
      "Average Precision: 0.8029\n",
      "Average Recall: 0.8028\n",
      "Average F1-score: 0.8023\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = sum([m[0] for m in metrics]) / len(metrics)\n",
    "avg_precision = sum([m[1] for m in metrics]) / len(metrics)\n",
    "avg_recall = sum([m[2] for m in metrics]) / len(metrics)\n",
    "avg_f1 = sum([m[3] for m in metrics]) / len(metrics)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def cross_validate_custom(data, pipeline, k=3):\n",
    "    folds = k_fold_split(data, k)\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(k):\n",
    "        logging.info(f\"=== Fold {i + 1}/{k} ===\")\n",
    "        validate_data = folds[i]\n",
    "        train_folds = [folds[j] for j in range(k) if j != i]\n",
    "        train_data = reduce(lambda df1, df2: df1.union(df2), train_folds)\n",
    "\n",
    "        model = pipeline.fit(train_data)\n",
    "        prediction = model.transform(validate_data).withColumn(\"prediction\", col(\"prediction\")[0].cast(\"string\"))\n",
    "        accuracy, precision, recall, f1 = evaluator(prediction, label_col=\"label\", prediction_col=\"prediction\")\n",
    "        metrics.append((accuracy, precision, recall, f1))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def run_grid_search_cv(data, k_fold=3):\n",
    "    lr_list = [0.003, 0.01]\n",
    "    batch_size_list = [8]\n",
    "    epoch_list = [5]\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_params = {}\n",
    "\n",
    "    for lr in lr_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            for epochs in epoch_list:\n",
    "                logging.info(f\"Running CV for lr={lr}, batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "                classifier = ClassifierDLApproach() \\\n",
    "                    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "                    .setOutputCol(\"category\") \\\n",
    "                    .setLabelColumn(\"label\") \\\n",
    "                    .setMaxEpochs(epochs) \\\n",
    "                    .setLr(lr) \\\n",
    "                    .setBatchSize(batch_size) \\\n",
    "                    .setEnableOutputLogs(False)\n",
    "\n",
    "                pipeline = Pipeline(stages=[\n",
    "                    DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\"),\n",
    "                    Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\"),\n",
    "                    Normalizer().setInputCols([\"token\"]).setOutputCol(\"normalized\").setLowercase(True),\n",
    "                    StopWordsCleaner().setInputCols([\"normalized\"]).setOutputCol(\"cleanTokens\").setCaseSensitive(False),\n",
    "                    LemmatizerModel.pretrained(\"lemma_antbnc\").setInputCols([\"cleanTokens\"]).setOutputCol(\"lemmatized\"),\n",
    "                    ElmoEmbeddings.pretrained(\"elmo\", \"en\").setInputCols([\"document\", \"lemmatized\"]).setOutputCol(\"embeddings\"),\n",
    "                    SentenceEmbeddings().setInputCols([\"document\", \"embeddings\"]).setOutputCol(\"sentence_embeddings\").setPoolingStrategy(\"AVERAGE\"),\n",
    "                    classifier,\n",
    "                    Finisher().setInputCols([\"category\"]).setOutputCols([\"prediction\"]).setCleanAnnotations(False)\n",
    "                ])\n",
    "\n",
    "                with mlflow.start_run(run_name=f\"CV_lr{lr}_bs{batch_size}_ep{epochs}\") as run:\n",
    "                    metrics = cross_validate_custom(data, pipeline, k=k_fold)\n",
    "                    avg_accuracy = sum([m[0] for m in metrics]) / len(metrics)\n",
    "                    avg_precision = sum([m[1] for m in metrics]) / len(metrics)\n",
    "                    avg_recall = sum([m[2] for m in metrics]) / len(metrics)\n",
    "                    avg_f1 = sum([m[3] for m in metrics]) / len(metrics)\n",
    "\n",
    "                    mlflow.log_param(\"lr\", lr)\n",
    "                    mlflow.log_param(\"batch_size\", batch_size)\n",
    "                    mlflow.log_param(\"maxEpochs\", epochs)\n",
    "                    mlflow.log_param(\"k_fold\", k_fold)\n",
    "\n",
    "                    mlflow.log_metric(\"avg_accuracy\", avg_accuracy)\n",
    "                    mlflow.log_metric(\"avg_precision\", avg_precision)\n",
    "                    mlflow.log_metric(\"avg_recall\", avg_recall)\n",
    "                    mlflow.log_metric(\"avg_f1\", avg_f1)\n",
    "\n",
    "                    if avg_f1 > best_f1:\n",
    "                        best_f1 = avg_f1\n",
    "                        best_params = {\"lr\": lr, \"batch_size\": batch_size, \"epochs\": epochs}\n",
    "                        logging.info(f\"New best F1: {best_f1:.4f} with {best_params}\")\n",
    "\n",
    "    logging.info(f\"Best result: F1={best_f1:.4f} with {best_params}\")\n",
    "    return best_params, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d15395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:22:13,472 - INFO - Running CV for lr=0.003, batch_size=8, epochs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:22:21,883 - INFO - === Fold 1/3 ===\n",
      "2025-06-03 10:27:26.782891: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/8849228df1f7_classifier_dl1773962856390756356\n",
      "2025-06-03 10:27:26.840734: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 10:27:26.840815: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/8849228df1f7_classifier_dl1773962856390756356\n",
      "2025-06-03 10:27:27.340335: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 10:27:28.571469: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/8849228df1f7_classifier_dl1773962856390756356\n",
      "2025-06-03 10:27:28.756151: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1973267 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 8 - training_examples: 39687 - classes: 3\n",
      "Epoch 1/5 - 23.90s - loss: 4492.515 - acc: 0.6418311 - batches: 4961\n",
      "Epoch 2/5 - 23.36s - loss: 4153.958 - acc: 0.7221486 - batches: 4961\n",
      "Epoch 3/5 - 22.92s - loss: 3917.5547 - acc: 0.7716446 - batches: 4961\n",
      "Epoch 4/5 - 24.68s - loss: 3751.4656 - acc: 0.80357504 - batches: 4961\n",
      "Epoch 5/5 - 27.88s - loss: 3636.135 - acc: 0.8250972 - batches: 4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:42:35,005 - INFO - === Fold 2/3 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7558\n",
      "Precision: 0.7564\n",
      "Recall:    0.7558\n",
      "F1-score:  0.7539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:47:33.963171: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/0b9bff23548f_classifier_dl18019890689534691922\n",
      "2025-06-03 10:47:34.025296: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 10:47:34.025352: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/0b9bff23548f_classifier_dl18019890689534691922\n",
      "2025-06-03 10:47:34.614089: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 10:47:35.695078: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/0b9bff23548f_classifier_dl18019890689534691922\n",
      "2025-06-03 10:47:35.848735: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1885572 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 8 - training_examples: 39466 - classes: 3\n",
      "Epoch 1/5 - 24.18s - loss: 4450.542 - acc: 0.63957024 - batches: 4934\n",
      "Epoch 2/5 - 24.86s - loss: 4122.7783 - acc: 0.7191111 - batches: 4934\n",
      "Epoch 3/5 - 24.17s - loss: 3880.0667 - acc: 0.7666988 - batches: 4934\n",
      "Epoch 4/5 - 24.10s - loss: 3714.915 - acc: 0.80252886 - batches: 4934\n",
      "Epoch 5/5 - 27.97s - loss: 3589.4832 - acc: 0.8256639 - batches: 4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:02:59,410 - INFO - === Fold 3/3 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7594\n",
      "Precision: 0.7590\n",
      "Recall:    0.7594\n",
      "F1-score:  0.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:07:38.705725: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/86f3e562b209_classifier_dl14455062086615724094\n",
      "2025-06-03 11:07:38.791451: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 11:07:38.791526: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/86f3e562b209_classifier_dl14455062086615724094\n",
      "2025-06-03 11:07:39.513010: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 11:07:41.613112: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/86f3e562b209_classifier_dl14455062086615724094\n",
      "2025-06-03 11:07:41.923166: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 3217453 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 8 - training_examples: 39841 - classes: 3\n",
      "Epoch 1/5 - 23.17s - loss: 4445.5645 - acc: 0.6431978 - batches: 4981\n",
      "Epoch 2/5 - 22.74s - loss: 4073.2725 - acc: 0.7239458 - batches: 4981\n",
      "Epoch 3/5 - 23.24s - loss: 3834.0652 - acc: 0.7714859 - batches: 4981\n",
      "Epoch 4/5 - 23.16s - loss: 3674.495 - acc: 0.8063755 - batches: 4981\n",
      "Epoch 5/5 - 23.72s - loss: 3563.5935 - acc: 0.82916665 - batches: 4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7617\n",
      "Precision: 0.7633\n",
      "Recall:    0.7617\n",
      "F1-score:  0.7594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:22:19,965 - INFO - New best F1: 0.7571 with {'lr': 0.003, 'batch_size': 8, 'epochs': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run CV_lr0.003_bs8_ep5 at: https://dagshub.com/TranChucThien/kltn-sentiment-monitoring-mlops.mlflow/#/experiments/63/runs/52b972d7e0614b01a5f9650dc80dd2ad\n",
      "🧪 View experiment at: https://dagshub.com/TranChucThien/kltn-sentiment-monitoring-mlops.mlflow/#/experiments/63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:22:20,654 - INFO - Running CV for lr=0.01, batch_size=8, epochs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:22:29,172 - INFO - === Fold 1/3 ===\n",
      "2025-06-03 11:27:24.639050: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/abb87c442a4a_classifier_dl14414614010468942213\n",
      "2025-06-03 11:27:24.793219: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 11:27:24.793296: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/abb87c442a4a_classifier_dl14414614010468942213\n",
      "2025-06-03 11:27:25.360390: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 11:27:26.265248: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/abb87c442a4a_classifier_dl14414614010468942213\n",
      "2025-06-03 11:27:26.447727: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1808688 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.01 - batch_size: 8 - training_examples: 39687 - classes: 3\n",
      "Epoch 1/5 - 22.61s - loss: 6000.825 - acc: 0.3371796 - batches: 4961\n",
      "Epoch 2/5 - 22.04s - loss: 6000.516 - acc: 0.3373056 - batches: 4961\n",
      "Epoch 3/5 - 23.15s - loss: 6000.516 - acc: 0.3373056 - batches: 4961\n",
      "Epoch 4/5 - 23.19s - loss: 6000.516 - acc: 0.3373056 - batches: 4961\n",
      "Epoch 5/5 - 23.66s - loss: 6000.516 - acc: 0.3373056 - batches: 4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:42:43,630 - INFO - === Fold 2/3 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3382\n",
      "Precision: 0.1144\n",
      "Recall:    0.3382\n",
      "F1-score:  0.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 11:48:12.559485: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/bc4ed32b338a_classifier_dl8706843278266446949\n",
      "2025-06-03 11:48:12.651621: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 11:48:12.651695: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/bc4ed32b338a_classifier_dl8706843278266446949\n",
      "2025-06-03 11:48:13.169785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 11:48:14.143728: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/bc4ed32b338a_classifier_dl8706843278266446949\n",
      "2025-06-03 11:48:14.314171: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1754697 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.01 - batch_size: 8 - training_examples: 39466 - classes: 3\n",
      "Epoch 1/5 - 25.78s - loss: 5804.101 - acc: 0.36836103 - batches: 4934\n",
      "Epoch 2/5 - 29.51s - loss: 5803.654 - acc: 0.36843705 - batches: 4934\n",
      "Epoch 3/5 - 27.54s - loss: 5803.654 - acc: 0.36843705 - batches: 4934\n",
      "Epoch 4/5 - 29.37s - loss: 5803.654 - acc: 0.36843705 - batches: 4934\n",
      "Epoch 5/5 - 27.26s - loss: 5803.654 - acc: 0.36843705 - batches: 4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 12:04:42,831 - INFO - === Fold 3/3 ===                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3644\n",
      "Precision: 0.1328\n",
      "Recall:    0.3644\n",
      "F1-score:  0.1946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 12:10:36.070251: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/63b80be1792f_classifier_dl13265948584870888484\n",
      "2025-06-03 12:10:36.196035: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2025-06-03 12:10:36.196258: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/63b80be1792f_classifier_dl13265948584870888484\n",
      "2025-06-03 12:10:36.955887: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2025-06-03 12:10:37.959790: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/63b80be1792f_classifier_dl13265948584870888484\n",
      "2025-06-03 12:10:38.177603: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2107361 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.01 - batch_size: 8 - training_examples: 39841 - classes: 3\n",
      "Epoch 1/5 - 23.86s - loss: 5875.1333 - acc: 0.36666667 - batches: 4981\n",
      "Epoch 2/5 - 23.50s - loss: 5874.5596 - acc: 0.36666667 - batches: 4981\n",
      "Epoch 3/5 - 23.31s - loss: 5874.5596 - acc: 0.36666667 - batches: 4981\n",
      "Epoch 4/5 - 22.53s - loss: 5874.5596 - acc: 0.36666667 - batches: 4981\n",
      "Epoch 5/5 - 24.53s - loss: 5874.5596 - acc: 0.36666667 - batches: 4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3679\n",
      "Precision: 0.1353\n",
      "Recall:    0.3679\n",
      "F1-score:  0.1979\n",
      "🏃 View run CV_lr0.01_bs8_ep5 at: https://dagshub.com/TranChucThien/kltn-sentiment-monitoring-mlops.mlflow/#/experiments/63/runs/ef9fbf47519f413c954ee11f8fc9cc93\n",
      "🧪 View experiment at: https://dagshub.com/TranChucThien/kltn-sentiment-monitoring-mlops.mlflow/#/experiments/63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 12:25:26,072 - INFO - Best result: F1=0.7571 with {'lr': 0.003, 'batch_size': 8, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "best_params, best_f1 = run_grid_search_cv(data, k_fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff687e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.003, 'batch_size': 8, 'epochs': 5}\n",
      "0.7571472894732002\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
